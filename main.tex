\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{dblfloatfix}
%\usepackage{flushend}
\usepackage{subcaption} %  for subfigures environments 
%\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
%\usepackage[all]{background}
%\usepackage{stackengine}
%\setstackEOL{\\}
%\setstackgap{L}{\normalbaselineskip}
%\SetBgContents{\color{blue}{\tiny \Longstack{PREPRINT - Accepted at the 43rd AIAA/IEEE Digital %Avionics Systems Conference (DASC), 2024.}}}% Set contents
%\SetBgPosition{4.5cm,1cm}% Select location
%\SetBgOpacity{1.0}% Select opacity
%\SetBgAngle{0}% Select rotation of logo
%\SetBgScale{1.8}% Select scale factor of logo

\begin{document}

\title{Evaluation of New Assurance Tools for Airborne Machine Learning-Based Functions\\
\thanks{Distribution statement ``A'' (approved for public release, distribution unlimited). This research was developed with funding from the Defense Advanced Research Projects Agency (DARPA), contract FA8750-18-C-0099. The views, opinions, or findings expressed are those of the authors and should not be interpreted as representing the official views or policies of the Department of Defense or the U.S. Government.}
}

\author{\IEEEauthorblockN{Cong Liu, Heber Herencia-Zapana, Saqib Hasan, Amer Tahat, Isaac Amundson,
        Darren Cofer}
\IEEEauthorblockA{\textit{Collins Aerospace} \\
\{first.last\}@collins.com}
}

\maketitle

\begin{abstract}
As part of the DARPA Assured Autonomy program, our team has developed or evaluated a number of technologies to address gaps in traditional hardware and software assurance processes that make it difficult or impossible to demonstrate the correctness and safety of machine learning (ML) components.    These include new approaches for testing and completeness metrics, formal analysis of neural networks, input domain shift assessment, and run-time monitoring and enforcement architectures.  Although many of these tools and methods were successfully applied to demonstration platforms, most have not been evaluated on real-world product development efforts in a certification context.  In this paper, we describe our evaluation of these new assurance methods and tools applied to ML-based systems that will soon be undergoing certification.
\end{abstract}

\begin{IEEEkeywords}
Assured Autonomy, neural network verification
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}
\input{introduction}

\section{Applications}
\label{sec:applications}
\input{applications}

\section{Formal Verification}
\label{sec:formalVerification}
\input{formalVerification}

\section{Out-Of-Distribution Monitoring}
\label{sec:outOfDistributionMonitoring}
\input{outOfDistributionMonitoring}

\section{Manifold-Based Test Generation}
\label{sec:manifoldBasedTestGeneration}
\input{manifoldBasedTestGeneration}

\section{Property Inference}
\label{sec:propertyInference}
\input{propertyInference}

\section{Conclusion}
\label{sec:conclusion}
\input{conclusion}


\bibliographystyle{IEEEtran}
\bibliography{biblio}


\end{document}
