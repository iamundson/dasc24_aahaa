Use of machine learning (ML) technology is expanding to support autonomy and other advanced functionality in safety/security-critical applications.  Unfortunately, when it comes to the regulatory approval of these systems, the certification guidance has not kept pace with the technology.

DO-178C, for example, provides guidance regarding software aspects of certification and is used by the commercial aviation industry and regulators as a means of compliance with airworthiness regulations. DO-178C fundamentally relies on requirements-based testing and structural coverage metrics for confidence that a software development process correctly implements a set of requirements. When requirements-based tests fail to exercise part of the software logic as revealed by structural coverage metrics, it is reasonable to conclude that either a requirement is missing, or the implementation includes unintended behavior. Since neural networks do not explicitly implement logical decisions, structural coverage can usually be achieved with a single test case and is therefore not helpful in identifying and eliminating unintended behaviors.  Because it is difficult to demonstrate assurance by examining the neural network design, other approaches are needed if we wish to take advantage of ML in our high-assurance applications.

As part of the DARPA Assured Autonomy (AA) program, our team has developed or evaluated a number of technologies to address gaps in traditional hardware and software assurance processes that make it difficult or impossible to demonstrate the correctness and safety of ML components.    These include new approaches for testing and completeness metrics, formal analysis of neural networks, input domain shift assessment, and run-time monitoring and enforcement architectures.  Although many of these tools and methods were successfully applied to demonstration platforms, most have not been evaluated on real-world product development efforts in a certification context. 

In this paper, we describe our evaluation of new assurance methods and tools applied to ML-based systems that will soon be undergoing certification.